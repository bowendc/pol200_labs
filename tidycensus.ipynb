{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0f5e1f1",
   "metadata": {},
   "source": [
    "# Downloading Census Data Using `tidycensus`\n",
    "\n",
    "`tidycensus` is an outstanding package that makes it much simpler to access and pull into R data from the U.S. Census Bureau. This lab introduces you to the core functions of the package. The goal of this lab is to generate measures of race and ethnicity by state and county. We'll use the American Community Survey, 5-year estimates for state-level data, and we'll use the 2020 decennial census for county-level data. Because the ACS is survey-based, they do not produce 5-year estimates for every county.  \n",
    "\n",
    "Let's load `tidyverse` and `tidycensus` using `pacman`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa42a1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load necessary packages - install only if needed\n",
    "\n",
    "#install.packages('pacman')\n",
    "\n",
    "pacman::p_load(tidyverse, tidycensus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07337bd2",
   "metadata": {},
   "source": [
    "## `load_variables()`\n",
    "\n",
    "The `load_variables()` function provides access to lists of variables from Census products. *It is not easy to identify which variables contain the information you need.* I recommend using this function to examine potential data sources. You will need to set the arguments in the function to define which dataset you want to pull variables from. Let's examine how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041095e1",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# write the output to a new dataframe:\n",
    "\n",
    "statevars <- load_variables(year = 2023, # set the year of the data\n",
    "                            dataset = \"acs5\" # set the file - these are the ACS 5-year estimates (2019-2023)\n",
    "                            )\n",
    "\n",
    "# find variables you want\n",
    "View(statevars)\n",
    "countyvars <- load_variables(year = 2020, # for our decennial census data\n",
    "                             dataset = \"dp\" # \"Demographic Profile\"\n",
    "                             )\n",
    "                        \n",
    "View(countyvars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c8333f",
   "metadata": {},
   "source": [
    "Finding the right variables is difficult! Be sure to figure out if you are identifying *counts* or *statistics*. Count data is the norm, and represents the number of people in the population with some characteristic. Some Census products will provide calculated states (percentages, medians, averages, etc). *If you are using count data, you will need to calculate your statistics. We almost never want only counts.*\n",
    "\n",
    "The Census Bureau nests variables. For example, if you were looking for educational attainment, the Bureau first will provide the total number of of people 25 and older. That's the relevant population. Then, it might provide the number of people with each level of educational attainment. And finally, it might provide those numbers broken down by some other variable, like race or sex. You need to understand the nesting structure of the data in order to grab the right measures of your concepts.\n",
    "\n",
    "The Census Bureau measures race and ethnicity as distinct concepts. Hispanic or Latino is consider an ethnicity, not a race. The way political scientists typically measure race and ethnicity is to code everyone who says their ethnicity is Hispanic or Latino as Latino, and then non-Latinos are coded base on their race. Of course, this is an overly-simplistic way of capturing complex identities. \n",
    "\n",
    "Below, I've pulled out the variables for white, black, Latino, and Asian populations. For white, black, and Asian, variables, they are coming from the \"Not Hispanic or Latino\" sub-population. However, in the ACS, these are measured as counts. So we also need to record the total population from that variable group. Notice that the demographic profile information from the 2020 Census calculates percentages for us and stores them in variables ending with a \"P\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c307de3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# since it is difficult to remember these variable names,\n",
    "#  assign the names you want to a list that we can use\n",
    "#  later.\n",
    "vars.st <- c(totalpop = \"B03002_001\",\n",
    "            white = \"B03002_003\",\n",
    "            black = \"B03002_004\",\n",
    "            latino = \"B03002_012\",\n",
    "            asian = \"B03002_006\")\n",
    "\n",
    "vars.cy <- c(latino = \"DP1_0096P\",\n",
    "            white = \"DP1_0105P\",\n",
    "            black = \"DP1_0106P\",\n",
    "            asian = \"DP1_0108P\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deba858a",
   "metadata": {},
   "source": [
    "# `get_acs()` and `get_decennial()` functions\n",
    "\n",
    "These functions allow us to pull in Census data using the Census Bureau's API. The functions are similar but not exactly the same. You will need to identify the *level of analysis* you want; place that information in the `geography` parameter. Both functions require you to provide information on the year and data source. The source is specified in the `survey` parameter in `get_acs()` and the `sumfile` parameter in `get_decennial()`. `sumfile` is a shortened version of \"summary file\", which is how the Census Bureau has historically released its decennial data. The `geometry` parameter will let you download geographic information for mapping. You won't be doing any mapping in this course, so you can set this argument to `FALSE`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce73b7dc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "states <- get_acs(geography = \"state\",\n",
    "                  year = 2023, \n",
    "                  survey = \"acs5\",\n",
    "                  variables = vars.st,      # calls up our stored list\n",
    "                  geometry = FALSE )        # you typically don't need the geometry data\n",
    "\n",
    "counties <- get_decennial(geography = \"county\",\n",
    "                  year = 2020, \n",
    "                  sumfile = \"dp\",\n",
    "                  variables = vars.cy,      \n",
    "                  geometry = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13302e",
   "metadata": {},
   "source": [
    "Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650323c7",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(states)\n",
    "head(counties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff38b7a6",
   "metadata": {},
   "source": [
    "Notice that in both cases, `tidycensus` provides different variables as *rows* instead of *columns*. As we've been doing throughout the semester, we can transpose our rows data into new columns using `pivot_wider`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3af2e3",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "states.wide <- states |> \n",
    "                    select(-moe) |>  # drops unneeded margin of error column from the ACS survey\n",
    "                    pivot_wider(names_from = \"variable\",\n",
    "                               values_from = \"estimate\")\n",
    "\n",
    "counties.wide <- counties |> \n",
    "                    pivot_wider(names_from = \"variable\",\n",
    "                               values_from = \"value\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1188d51",
   "metadata": {},
   "source": [
    "# Cleaning and processing data using loops and string functions\n",
    "\n",
    "In order to use our state-level estimates, we need to create a percentage. Again, don't use count data to measure demographic characteristics. We nearly always want percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e1065",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "states.wide <- states.wide |> \n",
    "                mutate(latino = 100 * latino / totalpop, \n",
    "                       white = 100 * white / totalpop,\n",
    "                       black = 100 * black / totalpop,\n",
    "                       asian = 100 * asian / totalpop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17782d3a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot() +\n",
    "    geom_density(data = counties.wide, aes(x = latino, y = ..density..),\n",
    "                fill = \"navy\", alpha = .3) +\n",
    "    geom_density(data = states.wide, aes(x = latino, y = ..density..),\n",
    "                fill = \"#282727\", alpha = .5) +\n",
    "    labs(x = \"Percent Latino/a\",\n",
    "         y = \"Density\",\n",
    "         title = \"Distribution of Percent Latino/a at County and State Levels\") +\n",
    "    theme_minimal() +\n",
    "    annotate(\"text\", x=10, y=.10, label = \"States\", color = \"navy\") +\n",
    "    annotate(\"text\", x=25, y=.025, label = \"Counties\", color = \"#282727\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe31c24",
   "metadata": {},
   "source": [
    "Now let's clean this up further and merge our county and state level data together into one dataframe. Before we merge, we need deal with the fact that variables are named the same thing in both dataframes. Let's rename the ones in the `states.wider` tibble using a simple loop. \n",
    "\n",
    "Loops repeat some action over multiple objects. The code below cycles through our race/ethnicity variables, stores a new variable name in object `q`, and then renames our existing variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b7a7e4",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# for loops work like this: \n",
    "# every time R sees an i, it will put insert the \n",
    "# named item in the list. It will repeat until every\n",
    "# item has been used. \n",
    "\n",
    "for(i in c(\"latino\",\"white\", \"black\", \"asian\")){ \n",
    "    q <- paste(i, \"st\", sep = \".\")\n",
    "    states.wide <- states.wide |> rename(!!q := .data[[i]])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f10ec5",
   "metadata": {},
   "source": [
    "A full explanation for what is happening inside of `rename` above is probably more advanced than we need to get, but this is what is needed for R to recognize our placeholders as variables. On the left-hand side of the equation, we use two exclamation marks (`!!`). On the right-hand side, we can get the column of data using`.data[[i]]`. Remember, `i` will be replaced with our variable name. One last wrinkle is that we need to use `:=` instead of `=` in order for this process to work. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943bc3ca",
   "metadata": {},
   "source": [
    "One final step is needed before we can merge. Currently, there is no variable for state in the county data. The state informantion is buried in the `GEOID` and `NAME` variables. The easiest was to solve this issue is to pull out the state identifying codes, called \"FIPS\" codes, from the `GEOID` variable. We can use the `substr()` function to manipulate the character variable and grab the first two characters of the code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8a6ace",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# substr(x,start,stop) will use some character string x\n",
    "# and then go from the starting character to the stopping character \n",
    "substr(\"1a2b3c\", 2, 4)\n",
    "\n",
    "# now let's use real data\n",
    "counties.wide <- counties.wide |> \n",
    "                    mutate(stfips = substr(GEOID,1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a5ae1f",
   "metadata": {},
   "source": [
    "Now we can merge using `left_join`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742db447",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "comb <- left_join(counties.wide,\n",
    "                  states.wide,\n",
    "                  by = join_by(stfips == GEOID))\n",
    "head(comb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8298acfa",
   "metadata": {},
   "source": [
    "Now, let's create a new variable that equals the difference between the county Percent Latino and the state's Percent Latino, and then graph the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585e276f",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "comb <- comb |> mutate(diff = latino - latino.st)\n",
    "\n",
    "ggplot(comb, aes(x = diff)) +\n",
    "    geom_density(fill = \"navy\", alpha = .3) +\n",
    "    labs(x = \"Difference\",\n",
    "         y = \"Density\",\n",
    "         title = \"Difference between County and State Percent Latino/a\") +\n",
    "    theme_minimal() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
